{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "87cbaafd-a46a-4bcc-8672-a82a15ceeb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('RDD Exampl').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bf23e1b6-fe45-4b86-a7c7-4455dc34bafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Create RDDs in three different ways. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8beef463-387b-416b-bca0-88574c62f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 4, 5]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (a)Create an RDD from a list\n",
    "data = [1, 2, 3, 4, 5]\n",
    "rdd = spark.sparkContext.parallelize(data)\n",
    "rdd.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d9f71032-66b9-42bd-8c74-0f953174b894",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a sample text file',\n",
       " 'this is a test file',\n",
       " 'is a file',\n",
       " 'is sample',\n",
       " 'text file',\n",
       " 'sample text',\n",
       " 'sample text file']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# (b)Create an RDD from a text file\n",
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "000933b1-9f02-486e-9235-1090b26a3d78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('file:/D:/sparkPrograms/RDD/rddfiles/test.txt',\n",
       "  'this is a sample text file\\r\\nthis is a test file\\r\\nis a file\\r\\nis sample\\r\\ntext file\\r\\nsample text\\r\\nsample text file'),\n",
       " ('file:/D:/sparkPrograms/RDD/rddfiles/test2.txt',\n",
       "  'this is a sample text file\\r\\nthis is a test file\\r\\nis a file\\r\\nis sample\\r\\ntext file\\r\\nsample text\\r\\nsample text file\\r\\nthis is a sample text file\\r\\nthis is a test file\\r\\nis a file\\r\\nis sample\\r\\ntext file\\r\\nsample text\\r\\nsample text file')]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#(c)Create an RDD from files in a directory\n",
    "rdd = spark.sparkContext.wholeTextFiles(\"D:/sparkPrograms/RDD/rddfiles/*\")\n",
    "rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7757a5fe-db27-41a7-af87-f53b8e5a0bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Read a text file and count the number of words in the file using RDD operations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b5a0947-f281-49fc-8323-4efd0133ab7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "words_rdd = rdd.flatMap(lambda line: line.split())\n",
    "words_rdd.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ffbc7b0b-90d4-4b03-866e-b0996c1569d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Write a program to find the word frequency in a given file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e6c723f2-bf97-4d18-839e-9bfff89d2697",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 2),\n",
       " ('sample', 4),\n",
       " ('text', 4),\n",
       " ('file', 5),\n",
       " ('is', 4),\n",
       " ('a', 3),\n",
       " ('test', 1)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "words_rdd = rdd.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "words_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7cdb00f9-80b4-492d-9225-a9668633c7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write a program to convert all words in a file to uppercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "0e8ec2fa-864b-4783-ac3b-85d96365b711",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['THIS',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'SAMPLE',\n",
       " 'TEXT',\n",
       " 'FILE',\n",
       " 'THIS',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'TEST',\n",
       " 'FILE',\n",
       " 'IS',\n",
       " 'A',\n",
       " 'FILE',\n",
       " 'IS',\n",
       " 'SAMPLE',\n",
       " 'TEXT',\n",
       " 'FILE',\n",
       " 'SAMPLE',\n",
       " 'TEXT',\n",
       " 'SAMPLE',\n",
       " 'TEXT',\n",
       " 'FILE']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "uppercase_rdd = rdd.flatMap(lambda line: line.split()).map(lambda word: word.upper())\n",
    "uppercase_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "30a8fcc2-d49a-449f-87d1-73b8cbf9d3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Write a program to convert all words in a file to lowercase. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "1498fdc4-c5fc-44ec-a8ac-1b3813db23e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'file',\n",
       " 'this',\n",
       " 'is',\n",
       " 'a',\n",
       " 'test',\n",
       " 'file',\n",
       " 'is',\n",
       " 'a',\n",
       " 'file',\n",
       " 'is',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'file',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'sample',\n",
       " 'text',\n",
       " 'file']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "lowercase_rdd = rdd.flatMap(lambda line: line.split()).map(lambda word: word.lower())\n",
    "lowercase_rdd.collect()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79602c2b-c287-4fb7-89a1-891f137972e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Write a program to capitalize first letter of each words in file (use string capitalize()  method). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9217758a-9148-48a4-9b26-92fc4fd8e8b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This',\n",
       " 'Is',\n",
       " 'A',\n",
       " 'Sample',\n",
       " 'Text',\n",
       " 'File',\n",
       " 'This',\n",
       " 'Is',\n",
       " 'A',\n",
       " 'Test',\n",
       " 'File',\n",
       " 'Is',\n",
       " 'A',\n",
       " 'File',\n",
       " 'Is',\n",
       " 'Sample',\n",
       " 'Text',\n",
       " 'File',\n",
       " 'Sample',\n",
       " 'Text',\n",
       " 'Sample',\n",
       " 'Text',\n",
       " 'File']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "capitalized_rdd = rdd.flatMap(lambda line: line.split()).map(lambda word: word.capitalize())\n",
    "capitalized_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "905e1af2-3886-47b7-b503-203596cb0b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['This Is A Sample Text File',\n",
       " 'This Is A Test File',\n",
       " 'Is A File',\n",
       " 'Is Sample',\n",
       " 'Text File',\n",
       " 'Sample Text',\n",
       " 'Sample Text File']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "capitalized_rdd = rdd.map(lambda line: ' '.join([word.capitalize() for word in line.split()]))\n",
    "capitalized_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b036df97-922b-4862-b4ef-6f08857e321a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Find the number of occurrence of a word in a given file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "011b5259-6c5f-4de4-988f-60e12d0ed14d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('this', 2),\n",
       " ('sample', 4),\n",
       " ('text', 4),\n",
       " ('file', 5),\n",
       " ('is', 4),\n",
       " ('a', 3),\n",
       " ('test', 1)]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "words_rdd = rdd.flatMap(lambda line: line.split()).map(lambda word: (word, 1)).reduceByKey(lambda a, b: a + b)\n",
    "words_rdd.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3d154ad1-db88-4276-9ca3-401cfb8aa9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Select only the sentences containing given word from a text file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "49213323-76d4-4f42-afde-7712677bbf26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this is a sample text file', 'is sample', 'sample text', 'sample text file']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_find = \"sample\"\n",
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "filtered_sentences = rdd.filter(lambda sentence: word_to_find.lower() in sentence.lower())\n",
    "filtered_sentences.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ef06c348-257d-40ac-9fe0-cd071941cfc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Find the longest length of word from given set of words. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "05af232f-dfb7-4337-83c1-875ed3da7062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watermelon\n"
     ]
    }
   ],
   "source": [
    "words = [\"apple\", \"banana\", \"cherry\", \"kiwi\", \"watermelon\"]\n",
    "rdd = spark.sparkContext.parallelize(words)\n",
    "longest_word = rdd.reduce(lambda x, y: x if len(x) > len(y) else y)\n",
    "print(longest_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f82860e1-869c-43be-aa60-9fdbdc031503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/test.txt\")\n",
    "longest_word = rdd.flatMap(lambda line: line.split()).reduce(lambda x, y: x if len(x) > len(y) else y)\n",
    "print(longest_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0d2d56b6-c170-409d-b71f-fb976e337061",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Map the Registration numbers to corresponding branch. \n",
    "# 58000 series BDA, 57000 series AIML, 38000 series VLSI, 39000 series ES, and 47000 series CDC. \n",
    "# Given registration number, generate a  key-value pair of Registration Number and Corresponding Branch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9d24c8f1-0236-4154-a1b2-107103409403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registration Number: 58001, Branch: BDA\n",
      "Registration Number: 57023, Branch: AIML\n",
      "Registration Number: 38045, Branch: VLSI\n",
      "Registration Number: 39012, Branch: ES\n",
      "Registration Number: 47056, Branch: CDC\n",
      "Registration Number: 58099, Branch: BDA\n",
      "Registration Number: 57088, Branch: AIML\n"
     ]
    }
   ],
   "source": [
    "registration_numbers = [58001, 57023, 38045, 39012, 47056, 58099, 57088]\n",
    "\n",
    "def map_registration_to_branch(reg_num):\n",
    "    if 58000 <= reg_num < 59000:\n",
    "        return \"BDA\"\n",
    "    elif 57000 <= reg_num < 58000:\n",
    "        return \"AIML\"\n",
    "    elif 38000 <= reg_num < 39000:\n",
    "        return \"VLSI\"\n",
    "    elif 39000 <= reg_num < 40000:\n",
    "        return \"ES\"\n",
    "    elif 47000 <= reg_num < 48000:\n",
    "        return \"CDC\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "rdd = spark.sparkContext.parallelize(registration_numbers)\n",
    "registration_branch_rdd = rdd.map(lambda reg_num: (reg_num, map_registration_to_branch(reg_num)))\n",
    "for reg_num, branch in registration_branch_rdd.collect():\n",
    "    print(f\"Registration Number: {reg_num}, Branch: {branch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "5821865e-ea17-4fe2-9a3b-148026918ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#11. Text file contain numbers. \n",
    "# Numbers are separated by one white space. \n",
    "# There is no order to store the numbers. \n",
    "# One line may contain one or more numbers.\n",
    "# Find the maximum, minimum, sum and mean of numbers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "aa91c39d-9202-41e2-a2b5-b6e80f3c9a9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum: 50\n",
      "Minimum: 1\n",
      "Sum: 280\n",
      "Mean: 18.666666666666668\n"
     ]
    }
   ],
   "source": [
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/numbers.txt\")\n",
    "\n",
    "numbers_rdd = rdd.flatMap(lambda line: line.split()).map(lambda x: int(x))\n",
    "\n",
    "max_value = numbers_rdd.max()\n",
    "min_value = numbers_rdd.min()\n",
    "sum_value = numbers_rdd.sum()\n",
    "count_value = numbers_rdd.count()\n",
    "mean_value = sum_value / count_value if count_value > 0 else 0  # Avoid division by zero\n",
    "\n",
    "print(f\"Maximum: {max_value}\")\n",
    "print(f\"Minimum: {min_value}\")\n",
    "print(f\"Sum: {sum_value}\")\n",
    "print(f\"Mean: {mean_value}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0e41b4e6-8104-4f9e-af20-5d27591fd49d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. A text file (citizen.txt) contains data about citizens of country. Fields(information in file) are Name, dob, Phone, email and state name. \n",
    "# Another file contains mapping of state names to state code like Karnataka is codes as KA, TamilNadu as TN, Kerala KL etc. \n",
    "# Compress the citizen.txt file by changing full state name to state code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "e209e1b0-da3c-4e6e-a045-609907b41538",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya MadhyaPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Rajastan\n",
      "Krish 50 Dwarka TamilNadu\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Gujart\n",
      "Krish 50 Dwarka Kerala\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya UP\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka MH\n",
      "Krish 50 Dwarka Karnataka\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Gopi 34 gopi@gmail.com Udupi KA\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Rama 23 761351431 rama@ayodhya.com Ayodhya Delhi\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka Telangana\n",
      "Krish 50 Dwarka AndraPradesh\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n",
      "Krishna 20 987124865 krishna@dwarka.com Dwarka KA\n",
      "Gopal 23 761351431 rama@ayodhya.com Mysore KA\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Step 1: Initialize SparkSession\n",
    "spark = SparkSession.builder.appName(\"StateCodeReplacement\").getOrCreate()\n",
    "\n",
    "# Step 2: Read the state codes mapping file and create a dictionary\n",
    "state_mapping = {}\n",
    "with open(\"D:/sparkPrograms/RDD/states.txt\", \"r\") as state_file:\n",
    "    for line in state_file:\n",
    "        line = line.strip()\n",
    "        if line:\n",
    "            parts = line.split(\" \")\n",
    "            if len(parts) == 2:\n",
    "                state_name, state_code = parts\n",
    "                state_mapping[state_name] = state_code\n",
    "            else:\n",
    "                print(f\"Skipping malformed line: {line}\")\n",
    "\n",
    "# Step 3: Read the citizen data from citizen.txt\n",
    "rdd = spark.sparkContext.textFile(\"D:/sparkPrograms/RDD/citizen.txt\")\n",
    "\n",
    "# Step 4: Function to replace the state name with state code\n",
    "def replace_state_name_with_code(line):\n",
    "    fields = line.split(\" \")\n",
    "    if len(fields) > 4:\n",
    "        state_name = fields[-1]\n",
    "        if state_name in state_mapping:\n",
    "            fields[-1] = state_mapping[state_name]\n",
    "    return \" \".join(fields)\n",
    "\n",
    "# Step 5: Apply the transformation to replace state names with state codes\n",
    "compressed_rdd = rdd.map(replace_state_name_with_code)\n",
    "\n",
    "# Step 6: Remove the output directory if it exists\n",
    "output_dir = \"D:/sparkPrograms/RDD/compressed_citizen.txt\"\n",
    "if os.path.exists(output_dir):\n",
    "    shutil.rmtree(output_dir)\n",
    "\n",
    "# Step 7: Save the compressed data to a new file\n",
    "compressed_rdd.saveAsTextFile(output_dir)\n",
    "\n",
    "# Step 8: If you want to view the output in the console (for testing)\n",
    "for line in compressed_rdd.collect():\n",
    "    print(line)\n",
    "\n",
    "# Stop the Spark session when done\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1e135d28-468f-484c-8834-736153a5e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (text file) with fields like ‘Student Name’, ‘Institute’, ‘Program Name’, and \n",
    "# ‘Gender’ and solve following questions.\n",
    "# 1. Compute number of students from each Institute.\n",
    "# 2. Number of students enrolled to any program.\n",
    "# 3. Number of ‘boy’ and ‘girl’ students.\n",
    "# 4. Number of ‘boy’ and ‘girl’ students from selected Institute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "f30a469c-15af-4712-a2aa-4a07e7f8d800",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of students from each Institute:\n",
      "Harvard: 2\n",
      "MIT: 4\n",
      "Stanford: 4\n",
      "\n",
      "Number of students enrolled in each program:\n",
      "Computer Science: 4\n",
      "Electrical Engineering: 2\n",
      "Civil Engineering: 2\n",
      "Mechanical Engineering: 2\n",
      "\n",
      "Number of 'boy' and 'girl' students:\n",
      "boy: 5\n",
      "girl: 5\n",
      "\n",
      "Number of 'boy' and 'girl' students from MIT:\n",
      "boy: 4\n"
     ]
    }
   ],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "\n",
    "# Reuse the existing SparkContext or create a new one if none exists\n",
    "sc = SparkContext.getOrCreate()\n",
    "\n",
    "# Step 1: Read the students dataset\n",
    "rdd = sc.textFile(\"D:/sparkPrograms/RDD/students.txt\")\n",
    "\n",
    "# Step 2: Split each line by commas and create an RDD of tuples\n",
    "students_rdd = rdd.map(lambda line: line.split(\", \"))\n",
    "\n",
    "# 1. Compute the number of students from each Institute\n",
    "institute_count = students_rdd.map(lambda student: (student[1], 1)) \\\n",
    "                              .reduceByKey(lambda x, y: x + y)\n",
    "print(\"Number of students from each Institute:\")\n",
    "for institute, count in institute_count.collect():\n",
    "    print(f\"{institute}: {count}\")\n",
    "\n",
    "# 2. Number of students enrolled in any program\n",
    "program_count = students_rdd.map(lambda student: (student[2], 1)) \\\n",
    "                            .reduceByKey(lambda x, y: x + y)\n",
    "print(\"\\nNumber of students enrolled in each program:\")\n",
    "for program, count in program_count.collect():\n",
    "    print(f\"{program}: {count}\")\n",
    "\n",
    "# 3. Number of ‘boy’ and ‘girl’ students\n",
    "gender_count = students_rdd.map(lambda student: (student[3], 1)) \\\n",
    "                           .reduceByKey(lambda x, y: x + y)\n",
    "print(\"\\nNumber of 'boy' and 'girl' students:\")\n",
    "for gender, count in gender_count.collect():\n",
    "    print(f\"{gender}: {count}\")\n",
    "\n",
    "# 4. Number of ‘boy’ and ‘girl’ students from a selected Institute (e.g., MIT)\n",
    "selected_institute = \"MIT\"\n",
    "gender_count_institute = students_rdd.filter(lambda student: student[1] == selected_institute) \\\n",
    "                                      .map(lambda student: (student[3], 1)) \\\n",
    "                                      .reduceByKey(lambda x, y: x + y)\n",
    "print(f\"\\nNumber of 'boy' and 'girl' students from {selected_institute}:\")\n",
    "for gender, count in gender_count_institute.collect():\n",
    "    print(f\"{gender}: {count}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "51644be2-46ce-4472-aabb-c32d51df2b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset: Temperature of Indian Cities. Fields of dataset are Date, Average Temperature, City, \n",
    "# Country, Latitude and Longitude (Use dataset attached to MapReduce assignment). Solve \n",
    "# following questions\n",
    "# 1. Find maximum and minimum temperature of all cities from the given dataset\n",
    "# 2. Count number of data point for each city.\n",
    "# 3. Find the maximum and minimum temperature for city Bangalore from the given dataset.\n",
    "# 4. Find the maximum and minimum temperature for any given city from the given dataset. \n",
    "# City name should be passed through command line argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ef52930e-d6e5-44e7-9869-7e07b1f8101b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------------------+---------+-------+--------+---------+\n",
      "|      Date|Average Temperature|     City|Country|Latitude|Longitude|\n",
      "+----------+-------------------+---------+-------+--------+---------+\n",
      "|2023-01-01|                 24|Bangalore|  India| 12.9716|  77.5946|\n",
      "|2023-01-02|                 25|Bangalore|  India| 12.9716|  77.5946|\n",
      "|2023-01-01|                 32|   Mumbai|  India|  19.076|  72.8777|\n",
      "|2023-01-02|                 33|   Mumbai|  India|  19.076|  72.8777|\n",
      "|2023-01-01|                 28|    Delhi|  India| 28.6139|   77.209|\n",
      "+----------+-------------------+---------+-------+--------+---------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Maximum Temperature of each City:\n",
      "+---------+------------------------+\n",
      "|     City|max(Average Temperature)|\n",
      "+---------+------------------------+\n",
      "|Bangalore|                      25|\n",
      "|  Chennai|                      36|\n",
      "|   Mumbai|                      33|\n",
      "|  Kolkata|                      28|\n",
      "|    Delhi|                      30|\n",
      "+---------+------------------------+\n",
      "\n",
      "Minimum Temperature of each City:\n",
      "+---------+------------------------+\n",
      "|     City|min(Average Temperature)|\n",
      "+---------+------------------------+\n",
      "|Bangalore|                      24|\n",
      "|  Chennai|                      35|\n",
      "|   Mumbai|                      32|\n",
      "|  Kolkata|                      27|\n",
      "|    Delhi|                      28|\n",
      "+---------+------------------------+\n",
      "\n",
      "Number of data points for each City:\n",
      "+---------+-----+\n",
      "|     City|count|\n",
      "+---------+-----+\n",
      "|Bangalore|    2|\n",
      "|  Chennai|    2|\n",
      "|   Mumbai|    2|\n",
      "|  Kolkata|    2|\n",
      "|    Delhi|    2|\n",
      "+---------+-----+\n",
      "\n",
      "Maximum Temperature in Bangalore:\n",
      "+------------------------+\n",
      "|max(Average Temperature)|\n",
      "+------------------------+\n",
      "|                      25|\n",
      "+------------------------+\n",
      "\n",
      "Minimum Temperature in Bangalore:\n",
      "+------------------------+\n",
      "|min(Average Temperature)|\n",
      "+------------------------+\n",
      "|                      24|\n",
      "+------------------------+\n",
      "\n",
      "Maximum Temperature in Chennai: 36\n",
      "Minimum Temperature in Chennai: 35\n"
     ]
    }
   ],
   "source": [
    "# Stop any existing SparkContext if it exists (to avoid multiple SparkContexts)\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Stop the existing SparkContext (if any)\n",
    "try:\n",
    "    sc.stop()\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# Create a new SparkSession\n",
    "spark = SparkSession.builder.appName(\"Temperature Data Analysis\").getOrCreate()\n",
    "\n",
    "# Read the dataset into a DataFrame\n",
    "df = spark.read.csv(\"D:/sparkPrograms/RDD/temperature_data.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Show the first few rows of the dataset\n",
    "df.show(5)\n",
    "\n",
    "# 1. Find maximum and minimum temperature of all cities from the given dataset\n",
    "max_temp = df.groupBy(\"City\").agg({\"Average Temperature\": \"max\"})\n",
    "min_temp = df.groupBy(\"City\").agg({\"Average Temperature\": \"min\"})\n",
    "\n",
    "print(\"Maximum Temperature of each City:\")\n",
    "max_temp.show()\n",
    "\n",
    "print(\"Minimum Temperature of each City:\")\n",
    "min_temp.show()\n",
    "\n",
    "# 2. Count number of data points for each city\n",
    "city_count = df.groupBy(\"City\").count()\n",
    "print(\"Number of data points for each City:\")\n",
    "city_count.show()\n",
    "\n",
    "# 3. Find the maximum and minimum temperature for the city Bangalore\n",
    "bangalore_data = df.filter(df[\"City\"] == \"Bangalore\")\n",
    "max_bangalore_temp = bangalore_data.agg({\"Average Temperature\": \"max\"})\n",
    "min_bangalore_temp = bangalore_data.agg({\"Average Temperature\": \"min\"})\n",
    "\n",
    "print(\"Maximum Temperature in Bangalore:\")\n",
    "max_bangalore_temp.show()\n",
    "\n",
    "print(\"Minimum Temperature in Bangalore:\")\n",
    "min_bangalore_temp.show()\n",
    "\n",
    "# 4. Find the maximum and minimum temperature for any given city from the dataset (using a dynamic city input)\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Function to get max and min temperature for any given city\n",
    "def get_city_temperature(city_name):\n",
    "    city_data = df.filter(df[\"City\"] == city_name)\n",
    "    max_temp = city_data.agg({\"Average Temperature\": \"max\"}).collect()[0][0]\n",
    "    min_temp = city_data.agg({\"Average Temperature\": \"min\"}).collect()[0][0]\n",
    "    print(f\"Maximum Temperature in {city_name}: {max_temp}\")\n",
    "    print(f\"Minimum Temperature in {city_name}: {min_temp}\")\n",
    "\n",
    "# Example usage: Get max and min temperatures for the city \"Chennai\"\n",
    "get_city_temperature(\"Chennai\")\n",
    "\n",
    "# Stop the SparkSession when done\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fea8c38b-1059-4da3-ab8c-6980b5e2eb62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset (text file) of bank transactions. Fields in file are ‘Bank ID’, ‘Account Number’, \n",
    "# ‘Transaction Date’, ‘Transaction Type’ (credit or debit), ‘Transaction Amount’. Date format is \n",
    "# dd-mm-yyyy.\n",
    "# 1. Count unique number of customers\n",
    "# 2. Count unique number of Bank ID\n",
    "# 3. Count unique number of customers per Bank ID\n",
    "# 4. Number of transactions for given Account Number\n",
    "# 5. Number of credit transactions for given Account Number in a given year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "84f4802d-7477-4967-802b-a3c6cd07627e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------+----------------+----------------+------------------+\n",
      "|Bank ID|Account Number|Transaction Date|Transaction Type|Transaction Amount|\n",
      "+-------+--------------+----------------+----------------+------------------+\n",
      "|   B001|        1001.0|      12-01-2023|          credit|            1500.0|\n",
      "|   B001|        1002.0|      13-01-2023|           debit|             500.0|\n",
      "|   B002|        1001.0|      14-01-2023|           debit|             200.0|\n",
      "|   B001|        1003.0|      15-01-2023|          credit|            1000.0|\n",
      "|   B002|        1004.0|      16-01-2023|          credit|            1200.0|\n",
      "+-------+--------------+----------------+----------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "Unique number of customers: 5\n",
      "Unique number of Bank IDs: 3\n",
      "+-------+----------------+\n",
      "|Bank ID|Unique Customers|\n",
      "+-------+----------------+\n",
      "|   B002|               4|\n",
      "|   B003|               2|\n",
      "|   B001|               3|\n",
      "+-------+----------------+\n",
      "\n",
      "Number of transactions for Account Number 1001: 3\n",
      "Number of credit transactions for Account Number 1001 in year 2023: 0\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, year, countDistinct\n",
    "\n",
    "# Create a Spark session\n",
    "spark = SparkSession.builder.appName(\"Bank Transactions Analysis\").getOrCreate()\n",
    "\n",
    "# Step 1: Load the data from the text file into a DataFrame\n",
    "df = spark.read.csv(\"D:/sparkPrograms/RDD/bank_transactions.txt\", header=False, inferSchema=True)\n",
    "\n",
    "# Rename the columns for clarity\n",
    "df = df.withColumnRenamed(\"_c0\", \"Bank ID\") \\\n",
    "       .withColumnRenamed(\"_c1\", \"Account Number\") \\\n",
    "       .withColumnRenamed(\"_c2\", \"Transaction Date\") \\\n",
    "       .withColumnRenamed(\"_c3\", \"Transaction Type\") \\\n",
    "       .withColumnRenamed(\"_c4\", \"Transaction Amount\")\n",
    "\n",
    "# Show a sample of the data\n",
    "df.show(5)\n",
    "\n",
    "# Step 2: Count unique number of customers (unique Account Numbers)\n",
    "unique_customers = df.select(\"Account Number\").distinct().count()\n",
    "print(f\"Unique number of customers: {unique_customers}\")\n",
    "\n",
    "# Step 3: Count unique number of Bank IDs\n",
    "unique_banks = df.select(\"Bank ID\").distinct().count()\n",
    "print(f\"Unique number of Bank IDs: {unique_banks}\")\n",
    "\n",
    "# Step 4: Count unique number of customers per Bank ID using countDistinct\n",
    "unique_customers_per_bank = df.groupBy(\"Bank ID\").agg(countDistinct(\"Account Number\").alias(\"Unique Customers\"))\n",
    "unique_customers_per_bank.show()\n",
    "\n",
    "# Step 5: Number of transactions for a given Account Number (e.g., Account Number 1001)\n",
    "account_number = 1001\n",
    "transactions_for_account = df.filter(df[\"Account Number\"] == account_number).count()\n",
    "print(f\"Number of transactions for Account Number {account_number}: {transactions_for_account}\")\n",
    "\n",
    "# Step 6: Number of credit transactions for a given Account Number in a given year (e.g., 2023, Account 1001)\n",
    "account_number = 1001\n",
    "year_value = 2023\n",
    "credit_transactions_for_account = df.filter(\n",
    "    (df[\"Account Number\"] == account_number) & \n",
    "    (df[\"Transaction Type\"] == \"credit\") & \n",
    "    (year(col(\"Transaction Date\")) == year_value)\n",
    ").count()\n",
    "\n",
    "print(f\"Number of credit transactions for Account Number {account_number} in year {year_value}: {credit_transactions_for_account}\")\n",
    "\n",
    "# Stop the Spark session when done\n",
    "spark.stop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244d360c-54bc-488b-910e-afe4f9606bfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
